{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95fa2649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[351   0  30   0   2   5   7]\n",
      " [  0 161   0   0   0   0   0]\n",
      " [ 11   0 451   0  11   1   5]\n",
      " [  0   0   0 958   1  17  67]\n",
      " [  0   0  13   6 555   0  14]\n",
      " [  4   0   0  12   0 587  16]\n",
      " [  3   0   1  89   7   6 693]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.95      0.89      0.92       395\n",
      "      BOMBAY       1.00      1.00      1.00       161\n",
      "        CALI       0.91      0.94      0.93       479\n",
      "    DERMASON       0.90      0.92      0.91      1043\n",
      "       HOROZ       0.96      0.94      0.95       588\n",
      "       SEKER       0.95      0.95      0.95       619\n",
      "        SIRA       0.86      0.87      0.87       799\n",
      "\n",
      "    accuracy                           0.92      4084\n",
      "   macro avg       0.93      0.93      0.93      4084\n",
      "weighted avg       0.92      0.92      0.92      4084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_excel('Dry_Bean_Dataset.xlsx')\n",
    "\n",
    "# 1. 缺失值处理\n",
    "data = data.dropna()\n",
    "\n",
    "# 定义特征和目标变量\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. 特征缩放 - 先使用 StandardScaler 进行标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. 特征缩放 - 使用 MinMaxScaler 进行归一化\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_normalized = min_max_scaler.fit_transform(X_train_scaled)\n",
    "X_test_normalized = min_max_scaler.transform(X_test_scaled)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_normalized, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test_normalized)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bd9a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林模型性能：\n",
      "准确率: 0.9233594515181195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.94      0.90      0.92       395\n",
      "      BOMBAY       1.00      1.00      1.00       161\n",
      "        CALI       0.92      0.94      0.93       479\n",
      "    DERMASON       0.90      0.93      0.92      1043\n",
      "       HOROZ       0.97      0.95      0.96       588\n",
      "       SEKER       0.94      0.94      0.94       619\n",
      "        SIRA       0.88      0.88      0.88       799\n",
      "\n",
      "    accuracy                           0.92      4084\n",
      "   macro avg       0.94      0.93      0.93      4084\n",
      "weighted avg       0.92      0.92      0.92      4084\n",
      "\n",
      "\n",
      "MLP模型性能：\n",
      "准确率: 0.925073457394711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.93      0.92      0.92       395\n",
      "      BOMBAY       1.00      1.00      1.00       161\n",
      "        CALI       0.93      0.94      0.94       479\n",
      "    DERMASON       0.93      0.90      0.91      1043\n",
      "       HOROZ       0.97      0.95      0.96       588\n",
      "       SEKER       0.94      0.95      0.95       619\n",
      "        SIRA       0.86      0.90      0.88       799\n",
      "\n",
      "    accuracy                           0.93      4084\n",
      "   macro avg       0.94      0.94      0.94      4084\n",
      "weighted avg       0.93      0.93      0.93      4084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# 随机森林模型训练\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,  # 树的数量\n",
    "    max_depth=20,       # 树的最大深度\n",
    "    random_state=42,\n",
    "    class_weight='balanced'  # 处理类别不平衡\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(\"随机森林模型性能：\")\n",
    "print(\"准确率:\", accuracy_score(y_test, rf_pred))\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "# MLP（多层感知机）模型训练\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "mlp_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),  # 两个隐藏层，分别有64和32个神经元\n",
    "    activation='relu',            # 激活函数\n",
    "    solver='adam',                # 优化算法\n",
    "    max_iter=200,                 # 最大迭代次数\n",
    "    random_state=42,\n",
    "    early_stopping=True           # 启用早停防止过拟合\n",
    ")\n",
    "\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "mlp_pred = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nMLP模型性能：\")\n",
    "print(\"准确率:\", accuracy_score(y_test, mlp_pred))\n",
    "print(classification_report(y_test, mlp_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "341c9f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "改进版MLP性能：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.96      0.87      0.91       395\n",
      "      BOMBAY       1.00      1.00      1.00       161\n",
      "        CALI       0.90      0.96      0.93       479\n",
      "    DERMASON       0.91      0.91      0.91      1043\n",
      "       HOROZ       0.98      0.92      0.95       588\n",
      "       SEKER       0.92      0.95      0.94       619\n",
      "        SIRA       0.85      0.87      0.86       799\n",
      "\n",
      "    accuracy                           0.92      4084\n",
      "   macro avg       0.93      0.93      0.93      4084\n",
      "weighted avg       0.92      0.92      0.92      4084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 优化尝试3：针对重叠区域的特征处理\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# 生成多项式特征（二次项）\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "X_train_poly = poly.fit_transform(X_train_normalized)\n",
    "X_test_poly = poly.transform(X_test_normalized)\n",
    "\n",
    "# 使用优化后的MLP\n",
    "mlp_improved = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 128, 64),  \n",
    "    activation='relu',\n",
    "    alpha=0.001,  # L2正则化\n",
    "    batch_size=64,\n",
    "    learning_rate='adaptive',\n",
    "    early_stopping=True,\n",
    "    random_state=42)\n",
    "\n",
    "mlp_improved.fit(X_train_poly, y_train)\n",
    "y_pred_mlp = mlp_improved.predict(X_test_poly)\n",
    "print(\"改进版MLP性能：\")\n",
    "print(classification_report(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3367dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化尝试5：使用Oversampling增强SIRA样本\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy={'SIRA': 2000},  # 适当增加SIRA样本\n",
    "              random_state=42,\n",
    "              k_neighbors=10)\n",
    "X_res, y_res = smote.fit_resample(X_train_poly, y_train)\n",
    "\n",
    "# 在增强数据上重新训练\n",
    "mlp_improved.fit(X_res, y_res)\n",
    "y_pred_smote = mlp_improved.predict(X_test_poly)\n",
    "print(\"SMOTE增强后的MLP性能：\")\n",
    "print(classification_report(y_test, y_pred_smote))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
